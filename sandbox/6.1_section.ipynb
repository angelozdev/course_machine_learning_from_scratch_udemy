{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b19880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"6.1_section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfenvnsffuh",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Initial Setup\n",
    "\n",
    "We start by importing necessary libraries and setting up logging for better debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fgfup37ruya",
   "metadata": {},
   "source": [
    "# NSL-KDD Network Intrusion Detection Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook explores the NSL-KDD dataset for network intrusion detection. We analyze network traffic patterns to understand the characteristics that distinguish normal traffic from anomalies/attacks.\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: NSL-KDD dataset (improved version of KDD Cup 1999)\n",
    "- **Purpose**: Binary classification (Normal vs Anomaly detection)\n",
    "- **Features**: 41 network traffic features + 1 target variable\n",
    "- **Classes**: \n",
    "  - `normal`: Legitimate network traffic\n",
    "  - `anomaly`: Malicious network traffic/attacks\n",
    "\n",
    "## Analysis Goals\n",
    "1. **Data Loading & Preprocessing**: Load and prepare the dataset\n",
    "2. **Exploratory Data Analysis**: Understand data distributions and patterns\n",
    "3. **Correlation Analysis**: Identify features most correlated with attack detection\n",
    "4. **Feature Engineering**: Prepare data for machine learning models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/NSL-KDD/KDDTrain+.txt', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "\n",
    "def load_arff_dataset(file_path: Path) -> pd.DataFrame:\n",
    "    logger.info(f\"Loading dataset from {file_path}\")\n",
    "\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset file not found: {file_path}\")\n",
    "\n",
    "    with file_path.open('r', encoding='utf-8') as file:\n",
    "        arff_data = arff.load(file)\n",
    "        arff_attributes = arff_data['attributes']\n",
    "        columns = [attr[0] for attr in arff_attributes]\n",
    "        data = arff_data['data']\n",
    "\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df = load_arff_dataset(Path('../datasets/NSL-KDD/KDDTrain+.arff'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ii6urr9syhe",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading\n",
    "\n",
    "Loading the NSL-KDD dataset from ARFF format. The ARFF format includes metadata about the dataset structure, making it more reliable than plain CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b062e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22zdj71llic",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration\n",
    "\n",
    "Let's examine the dataset structure, data types, and basic statistics to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406423bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conteo por clase:\")\n",
    "class_counts = df[\"class\"].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "print(\"Conteo relativo por clase:\")\n",
    "relative_class_counts = df[\"class\"].value_counts(normalize=True)\n",
    "print(relative_class_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('DistribuciÃ³n de Clases en el Conjunto de Datos')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('NÃºmero de Instancias')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dijvmqybz27",
   "metadata": {},
   "source": [
    "## 4. Class Distribution Analysis\n",
    "\n",
    "Understanding the balance between normal and anomaly classes is crucial for:\n",
    "- Choosing appropriate evaluation metrics\n",
    "- Deciding on sampling strategies\n",
    "- Understanding potential model bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = df.loc[df['class'] == 'normal']\n",
    "anomaly_df = df.loc[df['class'] == 'anomaly']\n",
    "\n",
    "variables = ['duration', 'src_bytes', 'dst_bytes', \"hot\", \"num_failed_logins\"]\n",
    "n_variables = len(variables)\n",
    "n_columns = 3\n",
    "n_rows = int(np.ceil(n_variables / n_columns))\n",
    "\n",
    "print(f\"NÃºmero de variables a graficar: {n_variables}\")\n",
    "print(f\"NÃºmero de columnas: {n_columns}\")\n",
    "print(f\"NÃºmero de filas: {n_rows}\")\n",
    "\n",
    "bins = 30\n",
    "fig, axes = plt.subplots(n_rows, n_columns, figsize=(12, 4 * n_rows))\n",
    "for i, var in enumerate(variables):\n",
    "    ax = axes[i // n_columns, i % n_columns]\n",
    "    normal_df[var].hist(ax=ax, label='Normal', alpha=0.5, bins=bins)\n",
    "    anomaly_df[var].hist(ax=ax, label='Anomaly', alpha=0.5, bins=bins)\n",
    "    ax.set_title(f'DistribuciÃ³n de {var}')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Densidad')\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xb2kcsvz6m",
   "metadata": {},
   "source": [
    "## 5. Feature Distribution Comparison\n",
    "\n",
    "Analyzing how key numerical features differ between normal and anomaly classes. This helps us understand:\n",
    "- Which features show clear separation between classes\n",
    "- The nature of the data distributions\n",
    "- Potential outliers and data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DistribuciÃ³n de protocolos por clase:\")\n",
    "protocol_by_class = df.groupby('class')['protocol_type'].value_counts(normalize=True).unstack()\n",
    "print(protocol_by_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9e39tp6g",
   "metadata": {},
   "source": [
    "## 6. Categorical Feature Analysis\n",
    "\n",
    "Examining categorical features like `protocol_type` to understand:\n",
    "- How different protocols relate to attack patterns\n",
    "- The distribution of network protocols in our dataset\n",
    "- Protocol-specific attack patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42889346",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "normal_protocols = normal_df['protocol_type'].value_counts()\n",
    "anomaly_protocols = anomaly_df['protocol_type'].value_counts()\n",
    "\n",
    "normal_protocols.plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "anomaly_protocols.plot(kind='bar', ax=axes[1], color='salmon')\n",
    "\n",
    "axes[0].set_title('Protocolos en Clase Normal')\n",
    "axes[1].set_title('Protocolos en Clase Anomaly')\n",
    "axes[0].set_xlabel('Protocolo')\n",
    "axes[1].set_xlabel('Protocolo')\n",
    "axes[0].set_ylabel('NÃºmero de Instancias')\n",
    "axes[1].set_ylabel('NÃºmero de Instancias')\n",
    "axes[0].grid(axis='y')\n",
    "axes[1].grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.copy()\n",
    "df_corr[\"class_num\"] = df_corr[\"class\"].map({\"normal\": 0, \"anomaly\": 1})\n",
    "df_corr = df_corr.drop(columns=[\"class\", \"protocol_type\", \"service\", \"flag\"])\n",
    "\n",
    "top_n = 5\n",
    "top_features = df_corr.corr()[\"class_num\"].abs().sort_values(ascending=False).head(top_n).index.to_list()\n",
    "correlation_matrix = df_corr[top_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, cmap=\"RdBu_r\", annot=True, center=0, linewidths=0.5, fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ciekz0st25v",
   "metadata": {},
   "source": [
    "### Key Correlation Insights\n",
    "\n",
    "From the correlation matrix above, we can observe:\n",
    "\n",
    "**ðŸ”´ Strong Positive Correlations** (Red - Higher values â†’ More likely anomaly):\n",
    "- **Error-related features**: `serror_rate`, `dst_host_serror_rate`, etc.\n",
    "- **Interpretation**: Anomalies are associated with network errors and failed connections\n",
    "\n",
    "**ðŸ”µ Strong Negative Correlations** (Blue - Higher values â†’ More likely normal):\n",
    "- **Service consistency features**: `same_srv_rate`, `dst_host_same_srv_rate`\n",
    "- **Login features**: `logged_in` status\n",
    "- **Interpretation**: Normal traffic shows consistent patterns and successful authentication\n",
    "\n",
    "**ðŸŸ¡ Feature Redundancy**:\n",
    "- Multiple error rate features show high correlation (0.95+) with each other\n",
    "- Suggests we could potentially reduce dimensionality without losing information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fxu1zr8nla",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis\n",
    "\n",
    "**Objective**: Identify which features have the strongest correlation with our target variable (`class`).\n",
    "\n",
    "This analysis helps us understand:\n",
    "- **Feature Importance**: Which features are most predictive\n",
    "- **Redundancy**: Features that provide similar information  \n",
    "- **Attack Patterns**: What network characteristics indicate anomalies\n",
    "\n",
    "**Methodology**:\n",
    "1. Convert categorical target to numeric: `normal=0, anomaly=1`\n",
    "2. Remove non-numeric features that can't be correlated\n",
    "3. Focus on top correlated features for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccca999",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"duration\", \"src_bytes\", \"dst_bytes\"]\n",
    "categorical_features = [\"protocol_type\"]\n",
    "binary_features = [\"class\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('n', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X = df.loc[:, numeric_features + categorical_features]\n",
    "y = df[binary_features]\n",
    "\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "X_transformed = pd.DataFrame(np.array(X_transformed), columns=preprocessor.get_feature_names_out())\n",
    "X_transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o3w5iuv8jeb",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering & Preprocessing\n",
    "\n",
    "**Purpose**: Prepare the data for machine learning models by:\n",
    "- **Scaling numerical features**: Ensure all features have similar ranges\n",
    "- **Encoding categorical features**: Convert text categories to numerical format\n",
    "- **Creating a clean feature matrix**: Ready for ML algorithms\n",
    "\n",
    "**Preprocessing Pipeline**:\n",
    "1. **StandardScaler**: Normalize numerical features (mean=0, std=1)\n",
    "2. **OneHotEncoder**: Convert categorical variables to binary columns\n",
    "3. **Drop first**: Avoid multicollinearity in categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6490b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "iqpyeqmvs8n",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### Key Findings from EDA:\n",
    "\n",
    "1. **Dataset Characteristics**:\n",
    "   - 125,973 samples with 42 features\n",
    "   - Binary classification: Normal vs Anomaly\n",
    "   - Mixed data types: numerical + categorical\n",
    "\n",
    "2. **Class Distribution**:\n",
    "   - Dataset shows class imbalance (check actual percentages)\n",
    "   - Important for model selection and evaluation metrics\n",
    "\n",
    "3. **Feature Insights**:\n",
    "   - **Error rates** are strong predictors of anomalies\n",
    "   - **Service consistency** patterns distinguish normal traffic\n",
    "   - **Protocol type** shows different attack patterns\n",
    "\n",
    "4. **Data Quality**:\n",
    "   - No missing values detected\n",
    "   - Some features show high correlation (potential redundancy)\n",
    "\n",
    "### Recommended Next Steps:\n",
    "\n",
    "1. **Feature Selection**: \n",
    "   - Use correlation insights to select most predictive features\n",
    "   - Consider removing highly correlated features\n",
    "\n",
    "2. **Model Development**:\n",
    "   - Start with simple models (Logistic Regression, Decision Trees)\n",
    "   - Progress to ensemble methods (Random Forest, XGBoost)\n",
    "\n",
    "3. **Evaluation Strategy**:\n",
    "   - Use appropriate metrics for imbalanced classes\n",
    "   - Implement cross-validation for robust evaluation\n",
    "\n",
    "4. **Advanced Analysis**:\n",
    "   - Explore specific attack types (if available in data)\n",
    "   - Time-series analysis for temporal patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
